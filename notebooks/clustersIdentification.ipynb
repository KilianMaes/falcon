{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analyze the clusters w.r.t. the spectrum identifications"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import bittremieux_utils\n",
    "from spectrum_utils.spectrum import MsmsSpectrum\n",
    "from ms_io import ms_io\n",
    "\n",
    "import spectrum_utils.plot as sup\n",
    "import spectrum_utils.spectrum as sus\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import the clustering file and load the identifications"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_labels = '/media/maesk/WD/MS/PXD000561/kim2014_ids.csv'\n",
    "labels = pd.read_csv(file_labels)\n",
    "labels['sequence'] = labels['sequence'].str.replace('L', 'I')\n",
    "\n",
    "cluster_labels = bittremieux_utils.get_clusters_falcon(\n",
    "    '/media/maesk/WD/falcon/PXD000561/nn/' + \\\n",
    "        'fragm_tol_0.05_hash_len_800/prec_tol_20/clusters_eps_0.1_minsample_2.csv',\n",
    "    labels\n",
    ")\n",
    "\n",
    "# Extract metadata from identifier\n",
    "development = []\n",
    "tissue = []\n",
    "spectrometer = []\n",
    "\n",
    "for id in cluster_labels['identifier'].tolist():\n",
    "    _, _, id, _, _ = id.split(':')\n",
    "    d, t, _, ms, _, _ = id.split('_')\n",
    "\n",
    "    development.append(d)\n",
    "    tissue.append(t)\n",
    "    spectrometer.append(ms)\n",
    "\n",
    "cluster_labels.insert(0, 'development', development)\n",
    "cluster_labels.insert(1, 'spectrometer', spectrometer)\n",
    "cluster_labels.insert(2, 'tissue', tissue)\n",
    "\n",
    "cluster_labels.sort_values(by='cluster', inplace=True)\n",
    "cluster_labels.reset_index(drop=True, inplace=True)\n",
    "cluster_labels.to_csv('/media/maesk/WD/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions to analyze/classify the clusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getMax(counter):\n",
    "    maj_key = max(counter.items(), key=operator.itemgetter(1))[0]\n",
    "    return maj_key, counter[maj_key]\n",
    "\n",
    "def clusterType(ids):\n",
    "    nsp_cl = len(ids)\n",
    "    count = Counter(ids)\n",
    "\n",
    "    # Get the key with larger count\n",
    "    maj_key, _ = getMax(count)\n",
    "    nlabeled = len([id for id in ids if not pd.isna(id)])\n",
    "    if len(count) == 1:\n",
    "        maj_identified = 0\n",
    "    else:\n",
    "        _, maj_identified = getMax(Counter([id for id in ids if not pd.isna(id)]))\n",
    "\n",
    "    if (count[maj_key] > 0.7*nsp_cl) and not pd.isna(maj_key):\n",
    "        type = 'identified'\n",
    "    elif count[maj_key] == nsp_cl and pd.isna(maj_key):\n",
    "        type = 'unidentified'\n",
    "    elif maj_identified > 0.7*nlabeled: # Most identifications are similar\n",
    "        type = 'coherent'\n",
    "    else:\n",
    "        type = 'incoherent'\n",
    "\n",
    "    return type, nlabeled/nsp_cl\n",
    "\n",
    "def majTissue(tissues):\n",
    "    nsp_cl = len(tissues)\n",
    "    count = Counter(tissues)\n",
    "    maj_tissue, cnt = getMax(count)\n",
    "    return maj_tissue, cnt/nsp_cl\n",
    "\n",
    "\n",
    "def addInterferences(interferences, sequences):\n",
    "    sequences = sequences.copy()\n",
    "    sequences = [s for s in sequences if not pd.isna(s)]\n",
    "    sequences = [s.split('/')[0] for s in sequences]\n",
    "    count = Counter(sequences)\n",
    "    for seq1, n1 in count.items():\n",
    "        for seq2, n2 in count.items():\n",
    "            if seq2 > seq1:\n",
    "                if seq1 not in interferences:\n",
    "                    interferences[seq1] = {}\n",
    "\n",
    "                if seq2 not in interferences[seq1]:\n",
    "                    interferences[seq1][seq2] = 0\n",
    "\n",
    "                interferences[seq1][seq2] = interferences[seq1][seq2] + n1*n2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make a summary with the info for each cluster"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nclusters = max(cluster_labels['cluster'])\n",
    "clids = []\n",
    "cltypes = []\n",
    "clsizes = []\n",
    "clproplabeleds = []\n",
    "maj_tissues = []\n",
    "prop_maj_tissues = []\n",
    "\n",
    "interferences = {}\n",
    "\n",
    "curr_cluster = 0\n",
    "\n",
    "clids = []\n",
    "curr_sequences = []\n",
    "curr_tissues = []\n",
    "curr_size = 0\n",
    "\n",
    "# Iterate over the dataframe\n",
    "for index, row in tqdm(cluster_labels.iterrows()):\n",
    "    if row['cluster'] == -1:\n",
    "        continue\n",
    "\n",
    "    if curr_cluster != row['cluster']:\n",
    "        cltype, prop = clusterType(curr_sequences)\n",
    "        cltypes.append(cltype)\n",
    "        clproplabeleds.append(prop)\n",
    "        clsizes.append(curr_size)\n",
    "        maj_tissue, prop_maj_tissue = majTissue(curr_tissues)\n",
    "        maj_tissues.append(maj_tissue)\n",
    "        prop_maj_tissues.append(prop_maj_tissue)\n",
    "        addInterferences(interferences, curr_sequences)\n",
    "\n",
    "        clids.append(curr_cluster)\n",
    "        curr_sequences = []\n",
    "        curr_tissues = []\n",
    "        curr_size = 0\n",
    "        curr_cluster = curr_cluster + 1\n",
    "\n",
    "        assert curr_cluster == row['cluster'] # Clusters should be ordered\n",
    "\n",
    "    curr_sequences.append(row['sequence'])\n",
    "    curr_tissues.append(row['tissue'])\n",
    "    curr_size = curr_size + 1\n",
    "\n",
    "cl_summary = pd.DataFrame({'id': clids, 'type':cltypes, 'size': clsizes,\n",
    "                           'prop_clustered': clproplabeleds,\n",
    "                           'maj_tissue': maj_tissues, 'prop_maj_tissue': prop_maj_tissues\n",
    "                           })\n",
    "cl_summary.sort_values(by='size', ascending=False).to_csv('summary_PXD0000561.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot the different \"types\" of clusters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bins = [2, 3, 5, 10, 20, 20000]\n",
    "\n",
    "labels = []\n",
    "sizes = {'unidentified': [], 'coherent': [],\n",
    "         'identified': [], 'incoherent': []}\n",
    "\n",
    "for i in range(0, len(bins)-1):\n",
    "    bottom, top = bins[i], bins[i+1]\n",
    "    labels.append('[%d,%d[' % (bottom, top))\n",
    "    for type, size in sizes.items():\n",
    "        mask1 = cl_summary['type'] == type\n",
    "        mask2 = (cl_summary['size'] >= bottom) & (cl_summary['size'] < top)\n",
    "        sizes[type].append(len(cl_summary[mask1 & mask2]))\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.20\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,4))\n",
    "b1 = axs[0].bar(x-width*1.5, sizes['identified'], width, label='Identified')\n",
    "b2 = axs[0].bar(x-width/2, sizes['unidentified'], width, label='Unidentified')\n",
    "b3 = axs[0].bar(x+width/2, sizes['coherent'], width, label='Coherent')\n",
    "b4 = axs[0].bar(x+width*1.5, sizes['incoherent'], width, label='Incoherent')\n",
    "\n",
    "axs[0].set_xlabel('Cluster size')\n",
    "axs[0].set_ylabel('Number of clusters')\n",
    "axs[0].set_title('Cluster sizes by cluster type')\n",
    "axs[0].set_xticks(x)\n",
    "axs[0].set_xticklabels(labels)\n",
    "axs[0].legend()\n",
    "\n",
    "labels = ['identified', 'unidentified', 'coherent', 'incoherent']\n",
    "axs[1].pie([sum(sizes[l]) for l in labels], labels=[l.capitalize() for l in labels], autopct='%1.1f%%')\n",
    "axs[1].set_title('Cluster types')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results_0.1/cluster_sizes.png', dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(cl_summary[(cl_summary['prop_maj_tissue'] == 1) & (cl_summary['type'] == 'unidentified')])/len(cl_summary))\n",
    "print(len(cl_summary[cl_summary['type'] == 'unidentified']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Test zone\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Show interferences as graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dataframe from the dic\n",
    "seq1 = []\n",
    "seq2 = []\n",
    "nintf = []\n",
    "\n",
    "for s1, d1 in interferences.items():\n",
    "    for s2, c2 in d1.items():\n",
    "        seq1.append(s1)\n",
    "        seq2.append(s2)\n",
    "        nintf.append(c2)\n",
    "\n",
    "interferences_df = pd.DataFrame({'seq1': seq1, 'seq2': seq2, 'count': nintf})\n",
    "interferences_df.sort_values(by='count', ascending=False, inplace=True)\n",
    "interferences_df.to_csv('results_0.1/interferences.csv')\n",
    "interferences_df.head()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Function to generate representative spectrum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def representative_spectrum(sps, consensus_identifier, min_intensity=0.01, max_num_peaks=1000, tol=0.05):\n",
    "    nsp = len(sps)\n",
    "\n",
    "    # Process the spectra\n",
    "    sps = [sp.filter_intensity(min_intensity, max_num_peaks) for sp in sps]\n",
    "\n",
    "    # Get all the peaks\n",
    "    peaks = []\n",
    "    for i in range(nsp):\n",
    "        sp = sps[i]\n",
    "        peaks = peaks + [(mz, intensity, {i}) for mz, intensity in zip(sp.mz, sp.intensity)]\n",
    "                    # (peak mz, peak intensity, ids of spectra having a peak at this position)\n",
    "\n",
    "    # Merge the closest pairs of peaks\n",
    "    while True:\n",
    "        peaks.sort()    # Sort by increasing mz\n",
    "        pair_scores = []\n",
    "\n",
    "        for i in range(len(peaks)-1):\n",
    "            mz_diff = peaks[i+1][0] - peaks[i][0]\n",
    "            if mz_diff < tol: # Always positive because ordered\n",
    "                pair_scores.append( (mz_diff, (i,i+1)) )\n",
    "\n",
    "        if len(pair_scores) == 0: # No more peaks can be merged\n",
    "            # Scale the peaks according to the probability they appear in a spectrum\n",
    "            # see Frank et al. https://pubs.acs.org/doi/abs/10.1021/pr070361e?casa_token=s05YEJTDKdsAAAAA:EEPc2E5byfAfCZtat1j4r65xOh5vFLtohaP0Zvs5cLuYZxZSN3axNyVBrk7dKzANbB69IFtHeHiX1ACp\n",
    "            scaled_peaks = []\n",
    "\n",
    "            for p in peaks:\n",
    "                prob = len(p[2]) / nsp\n",
    "                scaled_peaks.append( (p[0], p[1] * (0.95 + 0.05*(1+prob)**5)) )\n",
    "\n",
    "            return MsmsSpectrum(\n",
    "                consensus_identifier,\n",
    "                np.average([sp.precursor_mz for sp in sps]),\n",
    "                sps[0].precursor_charge,\n",
    "                [p[0] for p in scaled_peaks],\n",
    "                [p[1]/nsp for p in scaled_peaks]\n",
    "            ).filter_intensity(min_intensity, max_num_peaks)\n",
    "\n",
    "        # Merge the pair having the highest score\n",
    "        pair_scores.sort(reverse=True)\n",
    "        i = pair_scores[0][1]   # Peaks indices\n",
    "        p = peaks[i[0]], peaks[i[1]]\n",
    "        w = len(p[0][2]), len(p[1][2])\n",
    "        new_mz = (w[0]*p[0][0] + w[1]*p[1][0]) / (w[0] + w[1])\n",
    "        new_peak = (new_mz, p[0][1] + p[1][1], p[0][2].union(p[1][2]))\n",
    "\n",
    "        # Update the list of peaks\n",
    "        peaks.remove(p[0])\n",
    "        peaks.remove(p[1])\n",
    "        peaks.append(new_peak)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filter some clusters and export the corresponding spectra"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#mask = (cl_summary['type'] == 'unidentified') & \\\n",
    "#       (cl_summary['prop_maj_tissue'] == 1) & (cl_summary['size'] >= 20)\n",
    "#print('Number of large unidentified clusters: %d' % (sum(mask),))\n",
    "#cl_summary[mask].sort_values(by='size', ascending=False)\n",
    "exp =  [289001,\n",
    "        382377,\n",
    "        301107,\n",
    "        291997,\n",
    "        417060,\n",
    "        395555,\n",
    "        477049,\n",
    "        458065,\n",
    "        448727,\n",
    "        269290,\n",
    "        549144]\n",
    "\n",
    "mask = cl_summary['id'].isin(exp)\n",
    "print(sum(mask))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ms_io)\n",
    "\n",
    "sps_consensus_all = []\n",
    "id_clusters_all = []\n",
    "\n",
    "limit = 5000\n",
    "cnt = 0\n",
    "\n",
    "for index, row in tqdm(cl_summary[mask].iterrows(), total=len(cl_summary[mask])):\n",
    "    if cnt > limit:\n",
    "        break\n",
    "\n",
    "    id = row['id']\n",
    "\n",
    "    # Get the identifiers of the corresponding spectra\n",
    "    curr_sps = cluster_labels[cluster_labels['cluster'] == id]\n",
    "    #print(id, len(curr_sps))\n",
    "\n",
    "    # Load the bucket containing the spectra\n",
    "    precursor_charge = curr_sps['precursor_charge'].iloc[0]\n",
    "    mz_bucket = math.floor(curr_sps['precursor_mz'].iloc[0])\n",
    "\n",
    "    file_cl = 'consensus_0.1/repr_and_cluster/%d_%s_%d.mgf' % (row['size'], row['maj_tissue'], id)\n",
    "\n",
    "    #if path.isfile(file_cl):\n",
    "    #    continue\n",
    "\n",
    "    #print(curr_sps['identifier'].tolist())\n",
    "    sps = ms_io.get_one_spectrum_from_pkl(\n",
    "            '/media/maesk/WD/falcon/PXD000561/spectra',\n",
    "            precursor_charge, mz_bucket, curr_sps['identifier'].tolist())\n",
    "    #print(max(sps[0].intensity), max(sps[1].intensity))\n",
    "    sp_consensus = representative_spectrum(sps, 'consensus:%s:cluster_%d' % (row['maj_tissue'],id,))\n",
    "    sps_consensus_all.append(sp_consensus)\n",
    "\n",
    "    #print(sp_consensus.mz)\n",
    "    #print(sps[0].mz)\n",
    "\n",
    "    '''fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sup.mirror(sp_consensus,\n",
    "               sps[0],\n",
    "               ax=ax)\n",
    "    plt.show()\n",
    "    plt.close()'''\n",
    "\n",
    "    # Export the representative + the cluster\n",
    "    ms_io.write_spectra(file_cl, [sp_consensus] + sps)\n",
    "    cnt = cnt + 1\n",
    "\n",
    "# At the end, export all the representative spectra to mgf\n",
    "ms_io.write_spectra('consensus_0.1/5000_batch_3.mgf', sps_consensus_all)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% For each cluster, retrieve the spectra\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "falcon",
   "language": "python",
   "display_name": "falcon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}